---
title: 分类问题
tags:  [机器学习, 分类]
layout: post
description: 
comments: true
published: true
mathjax: true
categories: Machine-Learning
date: 2017-11-16 7:32:00 +0900
---

## 7-1 过拟合

过拟合是指模型过度拟合训练数据，而导致无法泛化去预测新的数据，即在训练数据上模型表现非常好，但在测试数据中表现很差。

[![](/assets/images/ML-7-1-2017-11-16-07-42-34.png)](https://www.bilibili.com/video/av9912938/index_39.html#page=40)

一般在特征过多，训练数据较少的时候会出现过度拟合的现象。解决过度拟合的办法一般是：

1. 减少特征数
  手动选择特征
  使用模型选择算法
1. 正则化
  保留所有的特征，但是减少特征的数量级
  在所有特征都能对结果产生一点点影响时非常有用

## 7-2 正则化代价函数

[![](/assets/images/ML-7-2-2017-11-17-19-00-23.png)](https://www.bilibili.com/video/av9912938/index_40.html#page=41)

正如上节提到的，为了避免过多特征参数造成过拟合，可以对代价函数正则化。正则化的核心思想可以参考上图，我们给代价函数加上$$1000\theta_3^2$$和$$1000\theta_4^2$$，这样一来，$$\theta_3$$和$$\theta_4$$只要发生微小的变化都会导致代价函数发生很大的变化，换句话说就是，给$$\theta_3$$和$$\theta_4$$加上一个比较大的惩罚，从而让它们接近于0。

由于并不知道应该选哪一个参数进行惩罚，于是给每一个参数都乘以一个$$\lambda$$，代价函数变成如下的形式：
![](/assets/images/ML-7-2-2017-11-17-19-37-05.png)

代价函数实现正则化后，训练就倾向于得到平滑的低维曲线：

![](/assets/images/ML-7-2-2017-11-17-19-32-19.png)

为什么正则化后的代价函数会起作用?
